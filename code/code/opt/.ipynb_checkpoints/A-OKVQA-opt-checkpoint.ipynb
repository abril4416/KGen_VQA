{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6051bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='12,13,14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e337288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "OK_PATH='/Data_Storage/Rui_Data_Space/VQA/OK-VQA'\n",
    "A_OK_PATH='/Data_Storage/Rui_Data_Space/VQA/A-OKVQA'\n",
    "PATH='/Data_Storage/Rui_Data_Space/VQA'\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b521cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "def load_pkl(path):\n",
    "    data=pkl.load(open(path,'rb'))\n",
    "    return data\n",
    "\n",
    "def load_json(path):\n",
    "    data=json.load(open(path,'r'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eda590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c7e04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "val_aokvqa=load_json(os.path.join(A_OK_PATH,'aokvqa_v1p0_val.json'))\n",
    "print(len(val_aokvqa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e511d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145 1145\n"
     ]
    }
   ],
   "source": [
    "ans_dict={}\n",
    "for row in val_aokvqa:\n",
    "    ques_id=str(row['question_id'])\n",
    "    answers=defaultdict(int)\n",
    "    for info in row['direct_answers']:\n",
    "        answers[info]+=1\n",
    "    #ans={ans:answers[ans]/sum(answers.values()) for ans in answers.keys()}\n",
    "    ans_dict[ques_id]=answers\n",
    "print (len(val_aokvqa),len(ans_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f704d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "captions=load_pkl('../EACL-24-results/aokvqa_val_captions_100.pkl')\n",
    "print (len(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1cb0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "OK_PATH='/Data_Storage/Rui_Data_Space/VQA/OK-VQA'\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3b9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a1df08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-22 15:34:35,326] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df9c14901e74796b9656f5786fdb1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-13b\", \n",
    "                                             torch_dtype=torch.float16, \n",
    "                                             device_map=\"auto\")\n",
    "\n",
    "# the fast tokenizer currently does not work correctly\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-13b\", \n",
    "                                          padding_side='left',\n",
    "                                          use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7615d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(occurences):\n",
    "    return min(1.0,occurences/3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1030f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "single = inflect.engine()\n",
    "\n",
    "def norm_ans(ans):\n",
    "    if ans.endswith(',') or ans.endswith('.'):\n",
    "        ans=ans[:-1]\n",
    "    if ans.startswith('a '):\n",
    "        ans=ans[2:]\n",
    "    if ',' in ans:\n",
    "        ans=ans.split(',')[0]\n",
    "    if len(ans.split(' '))==1 and ans not in ['grass','glass','bus']:\n",
    "        norm_ans=single.singular_noun(ans)\n",
    "        if norm_ans !=False:\n",
    "            ans=norm_ans\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2ad8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 4096, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 4096)\n",
       "      (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (12): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (13): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (14): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (15): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (16): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (17): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (18): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (19): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (20): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (21): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (22): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (23): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (24): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (25): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (26): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (27): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (28): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (29): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (30): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (31): OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "            (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9066974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "all_captions=load_pkl('../EACL-24-results/aokvqa_val_captions_100.pkl')\n",
    "print (len(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3125f899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "syn_qa_pairs=load_pkl('../EACL-24-results/a-ok_vqa_qa_img2llm.pkl')\n",
    "print(len(syn_qa_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "045a5b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 200\n",
      "\tAcc: 31.833333333333343\n",
      "Already finished: 400\n",
      "\tAcc: 34.16666666666666\n",
      "Already finished: 600\n",
      "\tAcc: 33.38888888888889\n",
      "Already finished: 800\n",
      "\tAcc: 33.29166666666667\n",
      "Already finished: 1000\n",
      "\tAcc: 34.66666666666667\n",
      "34.35225618631732\n"
     ]
    }
   ],
   "source": [
    "#30b\n",
    "NUM_DEMO=6\n",
    "NUM_KB=0\n",
    "NUM_CAP=15\n",
    "\n",
    "head='Please reason the answer of the questions according to the given contexts.\\n'\n",
    "def prompt_construction_kb(entry,ques,\n",
    "                           kb,\n",
    "                           contexts):\n",
    "    questions=entry['questions']\n",
    "    answers=entry['answers']\n",
    "    captions=entry['captions']\n",
    "    random.shuffle(captions)\n",
    "    all_texts=[head]\n",
    "    \"\"\"\n",
    "    remember to add KB\n",
    "    \"\"\"\n",
    "    all_texts.append('Contexts:'+' . '.join(captions[:NUM_DEMO])+'\\n')\n",
    "    #all_texts.append('Knowledge:'+' '.join(kb[:NUM_KB])+'\\n')\n",
    "    for i,q in enumerate(questions[:NUM_DEMO]):\n",
    "        all_texts.append('Question:'+q+'\\nAnswer:'+answers[i])\n",
    "    all_texts.append('Question:'+\\\n",
    "                     ques+\\\n",
    "                     '\\nAnswer:')\n",
    "    all_texts='\\n'.join(all_texts)\n",
    "    return all_texts\n",
    "\n",
    "#kb=0,num_cap=30,num_demo=15\n",
    "\n",
    "vis=0\n",
    "acc=0.0\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    if k>0 and k%200==0:\n",
    "        print ('Already finished:',vis)\n",
    "        print ('\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    ques=row['question']\n",
    "    answers=ans_dict[ques_id]\n",
    "    entry=syn_qa_pairs[ques_id]\n",
    "    kb=load_json(os.path.join('../A_OKVQA/cluster_generated_kb',\n",
    "                              ques_id+'.json'))\n",
    "    captions=all_captions[ques_id]\n",
    "    prompt=prompt_construction_kb(entry,ques,kb,captions)\n",
    "    #print (prompt)\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        output=model.generate(inputs['input_ids'].to(0), max_length=2000,\n",
    "                              length_penalty=-1,\n",
    "                              min_length=2,\n",
    "                              eos_token_id=50118)\n",
    "    pred=tokenizer.decode(output[0].tolist()).split(':')[-1].strip().lower()\n",
    "    pred=norm_ans(pred)\n",
    "    if pred in answers:\n",
    "        acc+=get_score(answers[pred])\n",
    "    #print('\\t',ques,ans_dict[ques_id])\n",
    "    #print (pred)\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51c891a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 200\n",
      "\tAcc: 34.66666666666667\n",
      "Already finished: 400\n",
      "\tAcc: 32.749999999999986\n",
      "Already finished: 600\n",
      "\tAcc: 33.72222222222223\n",
      "Already finished: 800\n",
      "\tAcc: 33.33333333333333\n",
      "Already finished: 1000\n",
      "\tAcc: 34.96666666666667\n",
      "35.05094614264918\n"
     ]
    }
   ],
   "source": [
    "#13b\n",
    "NUM_DEMO=15\n",
    "NUM_KB=0\n",
    "NUM_CAP=30\n",
    "\n",
    "head='Please reason the answer of the questions according to the given contexts.\\n'\n",
    "def prompt_construction_kb(entry,ques,\n",
    "                           kb,\n",
    "                           contexts):\n",
    "    questions=entry['questions']\n",
    "    answers=entry['answers']\n",
    "    captions=entry['captions']\n",
    "    random.shuffle(captions)\n",
    "    all_texts=[head]\n",
    "    \"\"\"\n",
    "    remember to add KB\n",
    "    \"\"\"\n",
    "    all_texts.append('Contexts:'+' . '.join(captions[:NUM_DEMO])+'\\n')\n",
    "    #all_texts.append('Knowledge:'+' '.join(kb[:NUM_KB])+'\\n')\n",
    "    for i,q in enumerate(questions[:NUM_DEMO]):\n",
    "        all_texts.append('Question:'+q+'\\nAnswer:'+answers[i])\n",
    "    all_texts.append('Question:'+\\\n",
    "                     ques+\\\n",
    "                     '\\nAnswer:')\n",
    "    all_texts='\\n'.join(all_texts)\n",
    "    return all_texts\n",
    "\n",
    "#kb=0,num_cap=30,num_demo=15\n",
    "\n",
    "vis=0\n",
    "acc=0.0\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    if k>0 and k%200==0:\n",
    "        print ('Already finished:',vis)\n",
    "        print ('\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    ques=row['question']\n",
    "    answers=ans_dict[ques_id]\n",
    "    entry=syn_qa_pairs[ques_id]\n",
    "    kb=load_json(os.path.join('../A_OKVQA/cluster_generated_kb',\n",
    "                              ques_id+'.json'))\n",
    "    captions=all_captions[ques_id]\n",
    "    prompt=prompt_construction_kb(entry,ques,kb,captions)\n",
    "    #print (prompt)\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        output=model.generate(inputs['input_ids'].to(0), max_length=2000,\n",
    "                              length_penalty=-1,\n",
    "                              min_length=2,\n",
    "                              eos_token_id=50118)\n",
    "    pred=tokenizer.decode(output[0].tolist()).split(':')[-1].strip().lower()\n",
    "    pred=norm_ans(pred)\n",
    "    if pred in answers:\n",
    "        acc+=get_score(answers[pred])\n",
    "    #print('\\t',ques,ans_dict[ques_id])\n",
    "    #print (pred)\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c22f8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 200\n",
      "\tAcc: 33.0\n",
      "Already finished: 400\n",
      "\tAcc: 31.666666666666657\n",
      "Already finished: 600\n",
      "\tAcc: 32.16666666666667\n",
      "Already finished: 800\n",
      "\tAcc: 32.708333333333336\n",
      "Already finished: 1000\n",
      "\tAcc: 32.43333333333334\n",
      "32.37263464337698\n"
     ]
    }
   ],
   "source": [
    "#6.7b\n",
    "NUM_DEMO=30\n",
    "NUM_KB=0\n",
    "NUM_CAP=30\n",
    "\n",
    "head='Please reason the answer of the questions according to the given contexts.\\n'\n",
    "def prompt_construction_kb(entry,ques,\n",
    "                           kb,\n",
    "                           contexts):\n",
    "    questions=entry['questions']\n",
    "    answers=entry['answers']\n",
    "    captions=entry['captions']\n",
    "    random.shuffle(captions)\n",
    "    all_texts=[head]\n",
    "    \"\"\"\n",
    "    remember to add KB\n",
    "    \"\"\"\n",
    "    all_texts.append('Contexts:'+' . '.join(captions[:NUM_DEMO])+'\\n')\n",
    "    #all_texts.append('Knowledge:'+' '.join(kb[:NUM_KB])+'\\n')\n",
    "    for i,q in enumerate(questions[:NUM_DEMO]):\n",
    "        all_texts.append('Question:'+q+'\\nAnswer:'+answers[i])\n",
    "    all_texts.append('Question:'+\\\n",
    "                     ques+\\\n",
    "                     '\\nAnswer:')\n",
    "    all_texts='\\n'.join(all_texts)\n",
    "    return all_texts\n",
    "\n",
    "#kb=0,num_cap=30,num_demo=15\n",
    "\n",
    "vis=0\n",
    "acc=0.0\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    if k>0 and k%200==0:\n",
    "        print ('Already finished:',vis)\n",
    "        print ('\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    ques=row['question']\n",
    "    answers=ans_dict[ques_id]\n",
    "    entry=syn_qa_pairs[ques_id]\n",
    "    kb=load_json(os.path.join('../A_OKVQA/cluster_generated_kb',\n",
    "                              ques_id+'.json'))\n",
    "    captions=all_captions[ques_id]\n",
    "    prompt=prompt_construction_kb(entry,ques,kb,captions)\n",
    "    #print (prompt)\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        output=model.generate(inputs['input_ids'].to(0), max_length=2000,\n",
    "                              length_penalty=-1,\n",
    "                              min_length=2,\n",
    "                              eos_token_id=50118)\n",
    "    pred=tokenizer.decode(output[0].tolist()).split(':')[-1].strip().lower()\n",
    "    pred=norm_ans(pred)\n",
    "    if pred in answers:\n",
    "        acc+=get_score(answers[pred])\n",
    "    #print('\\t',ques,ans_dict[ques_id])\n",
    "    #print (pred)\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd5555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcde45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b46a227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 200\n",
      "\tAcc: 35.66666666666667\n",
      "Already finished: 400\n",
      "\tAcc: 35.58333333333333\n",
      "Already finished: 600\n",
      "\tAcc: 35.61111111111111\n",
      "Already finished: 800\n",
      "\tAcc: 36.83333333333333\n",
      "Already finished: 1000\n",
      "\tAcc: 37.933333333333344\n",
      "38.13682678311499\n"
     ]
    }
   ],
   "source": [
    "#30b\n",
    "NUM_DEMO=6\n",
    "NUM_KB=5\n",
    "NUM_CAP=15\n",
    "\n",
    "head='Please reason the answer of the questions according to the given contexts.\\n'\n",
    "def prompt_construction_kb(entry,ques,\n",
    "                           kb,\n",
    "                           contexts):\n",
    "    questions=entry['questions']\n",
    "    answers=entry['answers']\n",
    "    captions=entry['captions']\n",
    "    random.shuffle(captions)\n",
    "    all_texts=[head]\n",
    "    \"\"\"\n",
    "    remember to add KB\n",
    "    \"\"\"\n",
    "    all_texts.append('Contexts:'+' . '.join(captions[:NUM_DEMO])+'\\n')\n",
    "    all_texts.append('Knowledge:'+' '.join(kb[:NUM_KB])+'\\n')\n",
    "    for i,q in enumerate(questions[:NUM_DEMO]):\n",
    "        all_texts.append('Question:'+q+'\\nAnswer:'+answers[i])\n",
    "    all_texts.append('Question:'+\\\n",
    "                     ques+\\\n",
    "                     '\\nAnswer:')\n",
    "    all_texts='\\n'.join(all_texts)\n",
    "    return all_texts\n",
    "\n",
    "#kb=0,num_cap=30,num_demo=15\n",
    "\n",
    "vis=0\n",
    "acc=0.0\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    if k>0 and k%200==0:\n",
    "        print ('Already finished:',vis)\n",
    "        print ('\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    ques=row['question']\n",
    "    answers=ans_dict[ques_id]\n",
    "    entry=syn_qa_pairs[ques_id]\n",
    "    kb=load_json(os.path.join('../A_OKVQA/cluster_generated_kb',\n",
    "                              ques_id+'.json'))\n",
    "    captions=all_captions[ques_id]\n",
    "    prompt=prompt_construction_kb(entry,ques,kb,captions)\n",
    "    #print (prompt)\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        output=model.generate(inputs['input_ids'].to(0), max_length=2000,\n",
    "                              length_penalty=-1,\n",
    "                              min_length=2,\n",
    "                              eos_token_id=50118)\n",
    "    pred=tokenizer.decode(output[0].tolist()).split(':')[-1].strip().lower()\n",
    "    pred=norm_ans(pred)\n",
    "    if pred in answers:\n",
    "        acc+=get_score(answers[pred])\n",
    "    #print('\\t',ques,ans_dict[ques_id])\n",
    "    #print (pred)\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b67e3951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 200\n",
      "\tAcc: 35.333333333333336\n",
      "Already finished: 400\n",
      "\tAcc: 35.16666666666667\n",
      "Already finished: 600\n",
      "\tAcc: 36.05555555555556\n",
      "Already finished: 800\n",
      "\tAcc: 35.416666666666664\n",
      "Already finished: 1000\n",
      "\tAcc: 36.26666666666667\n",
      "35.95342066957787\n"
     ]
    }
   ],
   "source": [
    "#13b\n",
    "NUM_DEMO=15\n",
    "NUM_KB=3\n",
    "NUM_CAP=30\n",
    "\n",
    "head='Please reason the answer of the questions according to the given contexts.\\n'\n",
    "def prompt_construction_kb(entry,ques,\n",
    "                           kb,\n",
    "                           contexts):\n",
    "    questions=entry['questions']\n",
    "    answers=entry['answers']\n",
    "    captions=entry['captions']\n",
    "    random.shuffle(captions)\n",
    "    all_texts=[head]\n",
    "    \"\"\"\n",
    "    remember to add KB\n",
    "    \"\"\"\n",
    "    all_texts.append('Contexts:'+' . '.join(captions[:NUM_DEMO])+'\\n')\n",
    "    all_texts.append('Knowledge:'+' '.join(kb[:NUM_KB])+'\\n')\n",
    "    for i,q in enumerate(questions[:NUM_DEMO]):\n",
    "        all_texts.append('Question:'+q+'\\nAnswer:'+answers[i])\n",
    "    all_texts.append('Question:'+\\\n",
    "                     ques+\\\n",
    "                     '\\nAnswer:')\n",
    "    all_texts='\\n'.join(all_texts)\n",
    "    return all_texts\n",
    "\n",
    "#kb=0,num_cap=30,num_demo=15\n",
    "\n",
    "vis=0\n",
    "acc=0.0\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    if k>0 and k%200==0:\n",
    "        print ('Already finished:',vis)\n",
    "        print ('\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    ques=row['question']\n",
    "    answers=ans_dict[ques_id]\n",
    "    entry=syn_qa_pairs[ques_id]\n",
    "    kb=load_json(os.path.join('../A_OKVQA/cluster_generated_kb',\n",
    "                              ques_id+'.json'))\n",
    "    captions=all_captions[ques_id]\n",
    "    prompt=prompt_construction_kb(entry,ques,kb,captions)\n",
    "    #print (prompt)\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        output=model.generate(inputs['input_ids'].to(0), max_length=2000,\n",
    "                              length_penalty=-1,\n",
    "                              min_length=2,\n",
    "                              eos_token_id=50118)\n",
    "    pred=tokenizer.decode(output[0].tolist()).split(':')[-1].strip().lower()\n",
    "    pred=norm_ans(pred)\n",
    "    if pred in answers:\n",
    "        acc+=get_score(answers[pred])\n",
    "    #print('\\t',ques,ans_dict[ques_id])\n",
    "    #print (pred)\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fdafd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 200\n",
      "\tAcc: 36.66666666666667\n",
      "Already finished: 400\n",
      "\tAcc: 35.50000000000001\n",
      "Already finished: 600\n",
      "\tAcc: 35.33333333333334\n",
      "Already finished: 800\n",
      "\tAcc: 35.666666666666664\n",
      "Already finished: 1000\n",
      "\tAcc: 35.933333333333344\n",
      "35.895196506550214\n"
     ]
    }
   ],
   "source": [
    "#6.7B\n",
    "NUM_DEMO=30\n",
    "NUM_KB=5\n",
    "NUM_CAP=30\n",
    "\n",
    "head='Please reason the answer of the questions according to the given contexts.\\n'\n",
    "def prompt_construction_kb(entry,ques,\n",
    "                           kb,\n",
    "                           contexts):\n",
    "    questions=entry['questions']\n",
    "    answers=entry['answers']\n",
    "    captions=entry['captions']\n",
    "    random.shuffle(captions)\n",
    "    all_texts=[head]\n",
    "    \"\"\"\n",
    "    remember to add KB\n",
    "    \"\"\"\n",
    "    all_texts.append('Contexts:'+' . '.join(captions[:NUM_DEMO])+'\\n')\n",
    "    all_texts.append('Knowledge:'+' '.join(kb[:NUM_KB])+'\\n')\n",
    "    for i,q in enumerate(questions[:NUM_DEMO]):\n",
    "        all_texts.append('Question:'+q+'\\nAnswer:'+answers[i])\n",
    "    all_texts.append('Question:'+\\\n",
    "                     ques+\\\n",
    "                     '\\nAnswer:')\n",
    "    all_texts='\\n'.join(all_texts)\n",
    "    return all_texts\n",
    "\n",
    "#kb=0,num_cap=30,num_demo=15\n",
    "\n",
    "vis=0\n",
    "acc=0.0\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    if k>0 and k%200==0:\n",
    "        print ('Already finished:',vis)\n",
    "        print ('\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    ques=row['question']\n",
    "    answers=ans_dict[ques_id]\n",
    "    entry=syn_qa_pairs[ques_id]\n",
    "    kb=load_json(os.path.join('../A_OKVQA/cluster_generated_kb',\n",
    "                              ques_id+'.json'))\n",
    "    captions=all_captions[ques_id]\n",
    "    prompt=prompt_construction_kb(entry,ques,kb,captions)\n",
    "    #print (prompt)\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        output=model.generate(inputs['input_ids'].to(0), max_length=2000,\n",
    "                              length_penalty=-1,\n",
    "                              min_length=2,\n",
    "                              eos_token_id=50118)\n",
    "    pred=tokenizer.decode(output[0].tolist()).split(':')[-1].strip().lower()\n",
    "    pred=norm_ans(pred)\n",
    "    if pred in answers:\n",
    "        acc+=get_score(answers[pred])\n",
    "    #print('\\t',ques,ans_dict[ques_id])\n",
    "    #print (pred)\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5483c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a47aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46328a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16776a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b07b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e514ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
