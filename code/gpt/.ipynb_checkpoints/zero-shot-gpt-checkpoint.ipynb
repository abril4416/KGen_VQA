{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b469a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "OK_PATH='/Data_Storage/Rui_Data_Space/VQA/OK-VQA'\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec17ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "def load_pkl(path):\n",
    "    data=pkl.load(open(path,'rb'))\n",
    "    return data\n",
    "\n",
    "def load_json(path):\n",
    "    data=json.load(open(path,'r'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e8029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b645ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046 5046\n"
     ]
    }
   ],
   "source": [
    "val_anno=load_json(os.path.join(OK_PATH,'mscoco_val2014_annotations.json'))['annotations']\n",
    "ans_dict={}\n",
    "for row in val_anno:\n",
    "    ques_id=str(row['question_id'])\n",
    "    answers=defaultdict(int)\n",
    "    for info in row['answers']:\n",
    "        answers[info['answer']]+=1\n",
    "    #ans={ans:answers[ans]/sum(answers.values()) for ans in answers.keys()}\n",
    "    ans_dict[ques_id]=answers\n",
    "print (len(val_anno),len(ans_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e24191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046\n"
     ]
    }
   ],
   "source": [
    "vqa_all=load_json(os.path.join(OK_PATH,'OpenEnded_mscoco_val2014_questions.json'))['questions']\n",
    "print (len(vqa_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0568b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046\n"
     ]
    }
   ],
   "source": [
    "vqa_all=load_json(os.path.join(OK_PATH,'OpenEnded_mscoco_val2014_questions.json'))['questions']\n",
    "print (len(vqa_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeba700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(occurences):\n",
    "    if occurences == 0:\n",
    "        return 0\n",
    "    elif occurences == 1:\n",
    "        return 0.3\n",
    "    elif occurences == 2:\n",
    "        return 0.6\n",
    "    elif occurences == 3:\n",
    "        return 0.9\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2220c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_cap=load_pkl(\"\"\"\n",
    "CAPTION_PATH\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d64b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "single = inflect.engine()\n",
    "\n",
    "def norm_ans(ans):\n",
    "    if ans.endswith(',') or ans.endswith('.'):\n",
    "        ans=ans[:-1]\n",
    "    if ans.startswith('a '):\n",
    "        ans=ans[2:]\n",
    "    if ',' in ans:\n",
    "        ans=ans.split(',')[0]\n",
    "    if len(ans.split(' '))==1 and ans not in ['grass','glass']:\n",
    "        norm_ans=single.singular_noun(ans)\n",
    "        if norm_ans !=False:\n",
    "            ans=norm_ans\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb1bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6845d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine_name='code-davinci-002'\n",
    "engine_name='text-davinci-003'\n",
    "temperature=0.0\n",
    "max_tokens=5\n",
    "top_p=0.75\n",
    "frequency_penalty=0.0\n",
    "presence_penalty=0.0\n",
    "num_sequence=1\n",
    "openai.api_key =open('../OK_VQA/openai_key.txt','r').readlines()[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "570f50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine_name='code-davinci-002'\n",
    "engine_name='text-davinci-003'\n",
    "temperature=0.0\n",
    "max_tokens=5\n",
    "top_p=0.75\n",
    "frequency_penalty=0.0\n",
    "presence_penalty=0.0\n",
    "num_sequence=1\n",
    "openai.api_key =open('../OK_VQA/mine.txt','r').readlines()[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1360879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "head='Please answer the question accordint to the above context with as few words as possible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5400f98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046\n",
      "Already finished: 0 0.0\n",
      "Already finished: 200 3.963535473642489\n",
      "\n",
      "\tAcc: 30.857142857142865\n",
      "Already finished: 400 7.927070947284978\n",
      "\n",
      "\tAcc: 29.714285714285722\n",
      "Already finished: 600 11.890606420927467\n",
      "\n",
      "\tAcc: 27.929515418502206\n",
      "Already finished: 800 15.854141894569956\n",
      "\n",
      "\tAcc: 28.184818481848186\n",
      "Already finished: 1000 19.817677368212447\n",
      "\n",
      "\tAcc: 26.595744680851055\n",
      "Already finished: 1200 23.781212841854934\n",
      "\n",
      "\tAcc: 26.377440347071566\n",
      "27.38522954091815\n"
     ]
    }
   ],
   "source": [
    "vis=0\n",
    "acc=0.0\n",
    "#random.shuffle(vqa_all)\n",
    "print (len(vqa_all))\n",
    "invalid=[]\n",
    "total={}\n",
    "for k,row in enumerate(vqa_all):\n",
    "    if vis>500:\n",
    "        break\n",
    "    if k%200==0:\n",
    "        print ('Already finished:',\n",
    "               k,k*100.0/len(vqa_all) )\n",
    "        if k>0:\n",
    "            print ('\\n\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    if os.path.exists(os.path.join('../OK_VQA/cluster_generated_kb',\n",
    "                                   ques_id+'.json'))==False:\n",
    "        continue\n",
    "    ques=row['question']\n",
    "    cap=ques_cap[ques_id]\n",
    "    kb=load_json(os.path.join('../OK_VQA/cluster_generated_kb',ques_id+'.json'))\n",
    "    inputs=[head+'\\n']\n",
    "    inputs.append('Context:'+cap)\n",
    "    inputs.append('Question:'+ques)\n",
    "    inputs.append('Answer:')\n",
    "    inputs='\\n'.join(inputs)\n",
    "    try:\n",
    "        response = openai.Completion.create(engine=engine_name,\n",
    "                                            prompt=inputs,\n",
    "                                            temperature=temperature,\n",
    "                                            max_tokens=max_tokens,\n",
    "                                            #top_p=top_p,\n",
    "                                            #logprobs=1,\n",
    "                                            #frequency_penalty=frequency_penalty,\n",
    "                                            #presence_penalty=presence_penalty,\n",
    "                                            stream=False,\n",
    "                                            stop=[\"\\n\"]\n",
    "                                           )\n",
    "        pred=response[\"choices\"][0][\"text\"].strip().lower()\n",
    "    except:\n",
    "        invalid.append(ques_id)\n",
    "        vis+=1\n",
    "        print (ques_id)\n",
    "        continue\n",
    "    ans=ans_dict[ques_id]\n",
    "        \n",
    "    pred=norm_ans(pred)\n",
    "    total[ques_id]=pred\n",
    "    if pred in ans_dict[ques_id]:\n",
    "        acc+=get_score(ans_dict[ques_id][pred])\n",
    "        \n",
    "    \"\"\"print(ques,ans)\n",
    "    print(cap)\n",
    "    print(pred)\n",
    "    img_id='COCO_val2014_'+str(row['image_id']).zfill(12)+'.jpg'\n",
    "    im=Image.open(os.path.join(OK_PATH,'images',img_id)).convert('RGB')\n",
    "    display(im)\"\"\"\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbde2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total,open('../EACL-24-results/zero-gpt-500.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6978bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40eb1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "head='Please answer the question accordint to the above context and knowledge with as few words as possible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689875a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bc73d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046\n",
      "Already finished: 0 0.0\n",
      "Already finished: 200 3.963535473642489\n",
      "\n",
      "\tAcc: 34.857142857142854\n",
      "Already finished: 400 7.927070947284978\n",
      "\n",
      "\tAcc: 31.714285714285722\n",
      "Already finished: 600 11.890606420927467\n",
      "\n",
      "\tAcc: 32.2466960352423\n",
      "4570785\n",
      "Already finished: 800 15.854141894569956\n",
      "\n",
      "\tAcc: 31.88118811881188\n",
      "Already finished: 1000 19.817677368212447\n",
      "\n",
      "\tAcc: 31.063829787234035\n",
      "Already finished: 1200 23.781212841854934\n",
      "\n",
      "\tAcc: 31.843817787418633\n",
      "32.41516966067862\n"
     ]
    }
   ],
   "source": [
    "vis=0\n",
    "acc=0.0\n",
    "NUM_KB=10\n",
    "#random.shuffle(vqa_all)\n",
    "print (len(vqa_all))\n",
    "invalid=[]\n",
    "total={}\n",
    "for k,row in enumerate(vqa_all):\n",
    "    if vis>500:\n",
    "        break\n",
    "    if k%200==0:\n",
    "        print ('Already finished:',\n",
    "               k,k*100.0/len(vqa_all) )\n",
    "        if k>0:\n",
    "            print ('\\n\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    if os.path.exists(os.path.join('../OK_VQA/cluster_generated_kb',\n",
    "                                   ques_id+'.json'))==False:\n",
    "        continue\n",
    "    ques=row['question']\n",
    "    cap=ques_cap[ques_id]\n",
    "    kb=load_json(os.path.join('../OK_VQA/cluster_generated_kb',ques_id+'.json'))\n",
    "    kb=kb[:NUM_KB]\n",
    "    kb=' . '.join(kb)\n",
    "    inputs=[head+'\\n']\n",
    "    inputs.append('Context:'+cap)\n",
    "    inputs.append('Knowledge:'+kb)\n",
    "    inputs.append('Question:'+ques)\n",
    "    inputs.append('Answer:')\n",
    "    inputs='\\n'.join(inputs)\n",
    "    try:\n",
    "        response = openai.Completion.create(engine=engine_name,\n",
    "                                            prompt=inputs,\n",
    "                                            temperature=temperature,\n",
    "                                            max_tokens=max_tokens,\n",
    "                                            #top_p=top_p,\n",
    "                                            #logprobs=1,\n",
    "                                            #frequency_penalty=frequency_penalty,\n",
    "                                            #presence_penalty=presence_penalty,\n",
    "                                            stream=False,\n",
    "                                            stop=[\"\\n\"]\n",
    "                                           )\n",
    "        pred=response[\"choices\"][0][\"text\"].strip().lower()\n",
    "    except:\n",
    "        invalid.append(ques_id)\n",
    "        vis+=1\n",
    "        print (ques_id)\n",
    "        continue\n",
    "    ans=ans_dict[ques_id]\n",
    "        \n",
    "    pred=norm_ans(pred)\n",
    "    total[ques_id]=pred\n",
    "    if pred in ans_dict[ques_id]:\n",
    "        acc+=get_score(ans_dict[ques_id][pred])\n",
    "        \n",
    "    \"\"\"print(ques,ans)\n",
    "    print(cap)\n",
    "    print(pred)\n",
    "    img_id='COCO_val2014_'+str(row['image_id']).zfill(12)+'.jpg'\n",
    "    im=Image.open(os.path.join(OK_PATH,'images',img_id)).convert('RGB')\n",
    "    display(im)\"\"\"\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b85d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total,open('../EACL-24-results/kb_10_zero-gpt-500.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8be19e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046\n",
      "Already finished: 0 0.0\n",
      "Already finished: 200 3.963535473642489\n",
      "\n",
      "\tAcc: 31.428571428571434\n",
      "Already finished: 400 7.927070947284978\n",
      "\n",
      "\tAcc: 29.2857142857143\n",
      "Already finished: 600 11.890606420927467\n",
      "\n",
      "\tAcc: 30.13215859030838\n",
      "Already finished: 800 15.854141894569956\n",
      "\n",
      "\tAcc: 30.495049504950494\n",
      "Already finished: 1000 19.817677368212447\n",
      "\n",
      "\tAcc: 30.478723404255305\n",
      "Already finished: 1200 23.781212841854934\n",
      "\n",
      "\tAcc: 31.32321041214749\n",
      "31.736526946107766\n"
     ]
    }
   ],
   "source": [
    "vis=0\n",
    "acc=0.0\n",
    "NUM_KB=20\n",
    "#random.shuffle(vqa_all)\n",
    "print (len(vqa_all))\n",
    "invalid=[]\n",
    "total={}\n",
    "for k,row in enumerate(vqa_all):\n",
    "    if vis>500:\n",
    "        break\n",
    "    if k%200==0:\n",
    "        print ('Already finished:',\n",
    "               k,k*100.0/len(vqa_all) )\n",
    "        if k>0:\n",
    "            print ('\\n\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    if os.path.exists(os.path.join('../OK_VQA/cluster_generated_kb',\n",
    "                                   ques_id+'.json'))==False:\n",
    "        continue\n",
    "    ques=row['question']\n",
    "    cap=ques_cap[ques_id]\n",
    "    kb=load_json(os.path.join('../OK_VQA/cluster_generated_kb',ques_id+'.json'))\n",
    "    kb=kb[:NUM_KB]\n",
    "    kb=' . '.join(kb)\n",
    "    inputs=[head+'\\n']\n",
    "    inputs.append('Context:'+cap)\n",
    "    inputs.append('Knowledge:'+kb)\n",
    "    inputs.append('Question:'+ques)\n",
    "    inputs.append('Answer:')\n",
    "    inputs='\\n'.join(inputs)\n",
    "    try:\n",
    "        response = openai.Completion.create(engine=engine_name,\n",
    "                                            prompt=inputs,\n",
    "                                            temperature=temperature,\n",
    "                                            max_tokens=max_tokens,\n",
    "                                            #top_p=top_p,\n",
    "                                            #logprobs=1,\n",
    "                                            #frequency_penalty=frequency_penalty,\n",
    "                                            #presence_penalty=presence_penalty,\n",
    "                                            stream=False,\n",
    "                                            stop=[\"\\n\"]\n",
    "                                           )\n",
    "        pred=response[\"choices\"][0][\"text\"].strip().lower()\n",
    "    except:\n",
    "        invalid.append(ques_id)\n",
    "        vis+=1\n",
    "        print (ques_id)\n",
    "        continue\n",
    "    ans=ans_dict[ques_id]\n",
    "        \n",
    "    pred=norm_ans(pred)\n",
    "    total[ques_id]=pred\n",
    "    if pred in ans_dict[ques_id]:\n",
    "        acc+=get_score(ans_dict[ques_id][pred])\n",
    "        \n",
    "    \"\"\"print(ques,ans)\n",
    "    print(cap)\n",
    "    print(pred)\n",
    "    img_id='COCO_val2014_'+str(row['image_id']).zfill(12)+'.jpg'\n",
    "    im=Image.open(os.path.join(OK_PATH,'images',img_id)).convert('RGB')\n",
    "    display(im)\"\"\"\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "359e0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total,open('../EACL-24-results/kb_20_zero-gpt-500.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00445ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdd84da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046\n",
      "Already finished: 0 0.0\n",
      "Already finished: 200 3.963535473642489\n",
      "\n",
      "\tAcc: 37.42857142857144\n",
      "Already finished: 400 7.927070947284978\n",
      "\n",
      "\tAcc: 32.71428571428572\n",
      "Already finished: 600 11.890606420927467\n",
      "\n",
      "\tAcc: 33.12775330396477\n",
      "Already finished: 800 15.854141894569956\n",
      "\n",
      "\tAcc: 34.059405940594054\n",
      "Already finished: 1000 19.817677368212447\n",
      "\n",
      "\tAcc: 33.56382978723402\n",
      "3548325\n",
      "Already finished: 1200 23.781212841854934\n",
      "\n",
      "\tAcc: 33.44902386117134\n",
      "34.09181636726544\n"
     ]
    }
   ],
   "source": [
    "vis=0\n",
    "acc=0.0\n",
    "NUM_KB=5\n",
    "#random.shuffle(vqa_all)\n",
    "print (len(vqa_all))\n",
    "invalid=[]\n",
    "total={}\n",
    "for k,row in enumerate(vqa_all):\n",
    "    if vis>500:\n",
    "        break\n",
    "    if k%200==0:\n",
    "        print ('Already finished:',\n",
    "               k,k*100.0/len(vqa_all) )\n",
    "        if k>0:\n",
    "            print ('\\n\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=str(row['question_id'])\n",
    "    if os.path.exists(os.path.join('../OK_VQA/cluster_generated_kb',\n",
    "                                   ques_id+'.json'))==False:\n",
    "        continue\n",
    "    ques=row['question']\n",
    "    cap=ques_cap[ques_id]\n",
    "    kb=load_json(os.path.join('../OK_VQA/cluster_generated_kb',ques_id+'.json'))\n",
    "    kb=kb[:NUM_KB]\n",
    "    kb=' . '.join(kb)\n",
    "    inputs= [head+'\\n']\n",
    "    inputs.append('Context:'+cap)\n",
    "    inputs.append('Knowledge:'+kb)\n",
    "    inputs.append('Question:'+ques)\n",
    "    inputs.append('Answer:')\n",
    "    inputs='\\n'.join(inputs)\n",
    "    try:\n",
    "        response = openai.Completion.create(engine=engine_name,\n",
    "                                            prompt=inputs,\n",
    "                                            temperature=temperature,\n",
    "                                            max_tokens=max_tokens,\n",
    "                                            #top_p=top_p,\n",
    "                                            #logprobs=1,\n",
    "                                            #frequency_penalty=frequency_penalty,\n",
    "                                            #presence_penalty=presence_penalty,\n",
    "                                            stream=False,\n",
    "                                            stop=[\"\\n\"]\n",
    "                                           )\n",
    "        pred=response[\"choices\"][0][\"text\"].strip().lower()\n",
    "    except:\n",
    "        invalid.append(ques_id)\n",
    "        vis+=1\n",
    "        print (ques_id)\n",
    "        continue\n",
    "    ans=ans_dict[ques_id]\n",
    "        \n",
    "    pred=norm_ans(pred)\n",
    "    total[ques_id]=pred\n",
    "    if pred in ans_dict[ques_id]:\n",
    "        acc+=get_score(ans_dict[ques_id][pred])\n",
    "        \n",
    "    \"\"\"print(ques,ans)\n",
    "    print(cap)\n",
    "    print(pred)\n",
    "    img_id='COCO_val2014_'+str(row['image_id']).zfill(12)+'.jpg'\n",
    "    im=Image.open(os.path.join(OK_PATH,'images',img_id)).convert('RGB')\n",
    "    display(im)\"\"\"\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5545108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total,open('../EACL-24-results/kb_5_zero-gpt-500.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe790a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c771146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a7630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
