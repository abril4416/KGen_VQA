{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3375d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92755800",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "OK_PATH='/Data_Storage/Rui_Data_Space/VQA/OK-VQA'\n",
    "A_OK_PATH='/Data_Storage/Rui_Data_Space/VQA/A-OKVQA'\n",
    "PATH='/Data_Storage/Rui_Data_Space/VQA'\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3940e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "def load_pkl(path):\n",
    "    data=pkl.load(open(path,'rb'))\n",
    "    return data\n",
    "\n",
    "def load_json(path):\n",
    "    data=json.load(open(path,'r'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10110790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946c9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0eef77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, AutoTokenizer\n",
    "model_name='bert-base-uncased'\n",
    "bert=BertModel.from_pretrained(model_name)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9917076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "#engine_name='code-davinci-002'\n",
    "engine_name='text-davinci-003'\n",
    "temperature=0.5\n",
    "max_tokens=128\n",
    "top_p=1\n",
    "frequency_penalty=0.0\n",
    "presence_penalty=0.0\n",
    "num_sequence=1\n",
    "openai.api_key =open('../OK_VQA/openai_key.txt','r').readlines()[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ae1f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17056 1145 6702\n"
     ]
    }
   ],
   "source": [
    "train_aokvqa=load_json(os.path.join(A_OK_PATH,'aokvqa_v1p0_train.json'))\n",
    "val_aokvqa=load_json(os.path.join(A_OK_PATH,'aokvqa_v1p0_val.json'))\n",
    "test_aokvqa=load_json(os.path.join(A_OK_PATH,'aokvqa_v1p0_test.json'))\n",
    "print(len(train_aokvqa),len(val_aokvqa),len(test_aokvqa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e57f00cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "captions=load_pkl('../EACL-24-results/aokvqa_val_captions_100.pkl')\n",
    "print (len(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438ce52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_info=load_pkl('../EACL-24-results/aokvqa_val_kb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03db75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70448009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ee60b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VIS=5\n",
    "NUM_CAP=5\n",
    "vis=0\n",
    "#random.shuffle(vqa_all)\n",
    "total_repre={}\n",
    "\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    \n",
    "    ques_id=str(row['question_id'])\n",
    "    if ques_id not in kb_info:\n",
    "        continue\n",
    "    kb=kb_info[ques_id]\n",
    "    ques=row['question']\n",
    "    cap=captions[ques_id]\n",
    "    context=cap[:NUM_CAP]\n",
    "    kb=kb_info[ques_id]\n",
    "    \n",
    "    all_sent=[]\n",
    "    all_sent.append('Question:'+ques)\n",
    "    all_sent.append('Context:'+' . '.join(context)+' . ')\n",
    "    all_sent.append('Knowledge:'+kb)\n",
    "    all_sent='\\n'.join(all_sent)\n",
    "    #print (all_sent)\n",
    "    tokens=tokenizer(all_sent, padding='longest', \n",
    "                     truncation=True, max_length=512,\n",
    "                     return_tensors=\"pt\").input_ids\n",
    "    repre=bert(tokens)[0][:,0].detach().squeeze().numpy()#768,\n",
    "    total_repre[ques_id]=repre\n",
    "    #print(repre.shape)\n",
    "    vis+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42ddad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total_repre,open('../EACL-24-results/a-okvqa-repre.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45130b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_repre=load_pkl('../EACL-24-results/a-okvqa-repre.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c01ac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "print (len(total_repre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a767ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "matrix=[]\n",
    "for name in total_repre.keys():\n",
    "    matrix.append(total_repre[name])\n",
    "print (len(matrix))\n",
    "names=list(total_repre.keys())\n",
    "\n",
    "NUM_CLUSTERS=8\n",
    "n_clusters = NUM_CLUSTERS\n",
    "kmeans = KMeans(n_clusters=n_clusters,\n",
    "                init='k-means++',\n",
    "                random_state=42)\n",
    "kmeans.fit(matrix)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcaf8a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "ques_id_label_mapper={}\n",
    "for i,name in enumerate(names):\n",
    "    ques_id_label_mapper[name]=labels[i]\n",
    "    \n",
    "print (len(ques_id_label_mapper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02db95f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 230\n",
      "1 \t 172\n",
      "2 \t 161\n",
      "3 \t 174\n",
      "4 \t 33\n",
      "5 \t 113\n",
      "6 \t 123\n",
      "7 \t 139\n"
     ]
    }
   ],
   "source": [
    "clustered_row={i:[] for i in range(NUM_CLUSTERS)}\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    ques_id=str(row['question_id'])\n",
    "    if ques_id not in kb_info:\n",
    "        continue\n",
    "    cluster_id=ques_id_label_mapper[ques_id]\n",
    "    clustered_row[cluster_id].append(row)\n",
    "for idx in range(NUM_CLUSTERS):\n",
    "    print (idx, '\\t',len(clustered_row[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0156d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CAP=3\n",
    "NUM_CLUSTERS=8\n",
    "def generate_context(row):\n",
    "    ques_id=str(row['question_id'])\n",
    "    cap=captions[ques_id]\n",
    "    context=cap[:NUM_CAP]\n",
    "    ques=row['question']\n",
    "    kb=kb_info[ques_id]\n",
    "    text=[]\n",
    "    text.append('Context:'+' . '.join(context))\n",
    "    text.append('Question:'+ques)\n",
    "    text.append('Knowledge:'+kb)\n",
    "    text='\\n'.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a4b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(label):\n",
    "    prompt_head='Please generate related background knowledge to the question:'\n",
    "    all_row=[]\n",
    "    all_row.append(prompt_head)\n",
    "    for idx in range(NUM_CLUSTERS):\n",
    "        if idx == label:\n",
    "            continue\n",
    "        cur_cluster=clustered_row[idx]\n",
    "        select_id=random.randint(0,len(cur_cluster)-1)\n",
    "        all_row.append(generate_context(cur_cluster[select_id]))\n",
    "    all_row='\\n\\n'.join(all_row)\n",
    "    return all_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d0af7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c50809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do some visualization\n",
    "NUM_QUERY_TIMES=20\n",
    "vis=0\n",
    "#time.sleep(60)\n",
    "invalid=defaultdict(int)\n",
    "all_names=[]\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    \"\"\"if vis>1500:\n",
    "        break\"\"\"\n",
    "    if k%100==0:\n",
    "        print ('Already finished:',\n",
    "               k,k*100.0/len(val_aokvqa),\n",
    "               '\\n\\tText rather than code:',\n",
    "               len(all_names),\n",
    "               len(os.listdir('../A_OKVQA/cluster_generated_kb')) )\n",
    "    #if vis>0:\n",
    "    #    break\n",
    "    ques_id=str(row['question_id'])\n",
    "\n",
    "    if os.path.exists('../A_OKVQA/cluster_generated_kb/'+ques_id+'.json'):\n",
    "        all_pieces=load_json('../A_OKVQA/cluster_generated_kb/'+ques_id+'.json')\n",
    "        if len(all_pieces)>=NUM_QUERY_TIMES:\n",
    "            continue\n",
    "    else:\n",
    "        all_pieces=[]\n",
    "    if ques_id not in kb_info:\n",
    "        label=random.randint(0,7)\n",
    "    else:\n",
    "        label=ques_id_label_mapper[ques_id]\n",
    "    all_names.append(ques_id)\n",
    "    #all_pieces=[]\n",
    "    \n",
    "    cap=captions[ques_id]\n",
    "    context=cap[:NUM_CAP]\n",
    "    ques=row['question']\n",
    "    #print(ques,'\\n',context)\n",
    "    if vis<3:\n",
    "        print (vis)\n",
    "        print(ques,'\\n',context)\n",
    "    for _ in range(NUM_QUERY_TIMES-len(all_pieces)):\n",
    "        demonstration=generate(label)\n",
    "        inputs=[demonstration]\n",
    "        inputs.append('\\nContext:'+'. '.join(context))\n",
    "        inputs.append('Question:'+ques)\n",
    "        inputs='\\n'.join(inputs)+'\\nKnowledge:'\n",
    "        try:\n",
    "            response = openai.Completion.create(engine=engine_name,\n",
    "                                                prompt=inputs,\n",
    "                                                temperature=temperature,\n",
    "                                                max_tokens=max_tokens,\n",
    "                                                top_p=top_p,\n",
    "                                                frequency_penalty=frequency_penalty,\n",
    "                                                presence_penalty=presence_penalty,\n",
    "                                                stop=[\"\\n\"])\n",
    "            knowledge=response[\"choices\"][0][\"text\"].strip()\n",
    "            all_pieces.append(knowledge)\n",
    "            if vis<3:\n",
    "                print ('\\t',knowledge)\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            invalid[ques_id]+=1\n",
    "            #openai.api_key =open('OK_VQA/openai_key.txt','r').readlines()[0].strip()\n",
    "            print ('Invalid id:',ques_id)\n",
    "            #time.sleep(0.5)\n",
    "    #print ('\\n')\n",
    "    json.dump(all_pieces,\n",
    "              open(\n",
    "                  '../A_OKVQA/cluster_generated_kb/'+ques_id+'.json',\n",
    "                  'w'))\n",
    "    \n",
    "    if vis<3:\n",
    "        print ('\\n')\n",
    "    vis+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
