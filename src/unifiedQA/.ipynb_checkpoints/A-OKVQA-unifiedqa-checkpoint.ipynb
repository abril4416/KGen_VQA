{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c88d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bce72cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "OK_PATH='/Data_Storage/Rui_Data_Space/VQA/OK-VQA'\n",
    "A_OK_PATH='/Data_Storage/Rui_Data_Space/VQA/A-OKVQA'\n",
    "PATH='/Data_Storage/Rui_Data_Space/VQA'\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9c7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "def load_pkl(path):\n",
    "    data=pkl.load(open(path,'rb'))\n",
    "    return data\n",
    "\n",
    "def load_json(path):\n",
    "    data=json.load(open(path,'r'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4b17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1c6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-22 07:12:21,153] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from lavis.common.gradcam import getAttMap\n",
    "from lavis.models import load_model_and_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33cc7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE=1\n",
    "torch.cuda.set_device(CUDA_DEVICE)\n",
    "device = torch.device(\"cuda:\"+str(CUDA_DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4f5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vis_processors, txt_processors = load_model_and_preprocess(name=\"pnp_vqa\", model_type=\"3b\", \n",
    "                                                                  is_eval=True,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75bc00ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "val_aokvqa=load_json(os.path.join(A_OK_PATH,'aokvqa_v1p0_val.json'))\n",
    "print(len(val_aokvqa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bca2050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145 1145\n"
     ]
    }
   ],
   "source": [
    "ans_dict={}\n",
    "for row in val_aokvqa:\n",
    "    ques_id=str(row['question_id'])\n",
    "    answers=defaultdict(int)\n",
    "    for info in row['direct_answers']:\n",
    "        answers[info]+=1\n",
    "    #ans={ans:answers[ans]/sum(answers.values()) for ans in answers.keys()}\n",
    "    ans_dict[ques_id]=answers\n",
    "print (len(val_aokvqa),len(ans_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3e84c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "captions=load_pkl('../EMNLP-23-results/aokvqa_val_captions_100.pkl')\n",
    "print (len(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2ce1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(occurences):\n",
    "    return min(1.0,occurences/3.0)\n",
    "\n",
    "import inflect\n",
    "single = inflect.engine()\n",
    "\n",
    "def norm_ans(ans):\n",
    "    if ans.startswith('a '):\n",
    "        ans=ans[2:]\n",
    "    if ',' in ans:\n",
    "        ans=ans.split(',')[0]\n",
    "    if len(ans.split(' '))==1 and ans not in ['grass','glass']:\n",
    "        norm_ans=single.singular_noun(ans)\n",
    "        if norm_ans !=False:\n",
    "            ans=norm_ans\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da817c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a16955fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 0 0.0\n",
      "Already finished: 200 17.467248908296945\n",
      "\n",
      "\tAcc: 31.833333333333336\n",
      "Already finished: 400 34.93449781659389\n",
      "\n",
      "\tAcc: 33.33333333333333\n",
      "Already finished: 600 52.40174672489083\n",
      "\n",
      "\tAcc: 33.88888888888889\n",
      "Already finished: 800 69.86899563318778\n",
      "\n",
      "\tAcc: 35.16666666666667\n",
      "Already finished: 1000 87.33624454148472\n",
      "\n",
      "\tAcc: 35.79999999999999\n",
      "35.487627365356616\n",
      "1145\n"
     ]
    }
   ],
   "source": [
    "vis=0\n",
    "acc=0.0\n",
    "NUM_CAP=65\n",
    "total={}\n",
    "NUM_KB=0\n",
    "#random.shuffle(val_aokvqa)\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    \"\"\"if vis>5:\n",
    "        break\"\"\"\n",
    "    if k%200==0:\n",
    "        print ('Already finished:',\n",
    "               k,k*100.0/len(val_aokvqa) )\n",
    "        if k>0:\n",
    "            print ('\\n\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=row['question_id']\n",
    "    img_id=str(row['image_id'])\n",
    "    img_id=img_id.zfill(12)+'.jpg'\n",
    "    img_path=os.path.join(PATH,'COCO-2017/val2017',img_id)\n",
    "    im=Image.open(img_path).convert('RGB')\n",
    "    image = vis_processors[\"eval\"](im).unsqueeze(0).to(device)\n",
    "    text=row['question']\n",
    "    question = txt_processors[\"eval\"](text)\n",
    "    samples = {\"image\": image, \"text_input\": [question]}\n",
    "    caption=captions[ques_id]\n",
    "    samples['captions']=[caption[:NUM_CAP]]\n",
    "    pred_answers = model.forward_qa(samples,\n",
    "                                    num_captions=NUM_CAP)\n",
    "    pred=norm_ans(pred_answers[0].lower())\n",
    "    total[ques_id]=pred\n",
    "    if pred in ans_dict[ques_id]:\n",
    "        acc+=get_score(ans_dict[ques_id][pred])\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)\n",
    "print (vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c4beea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already finished: 0 0.0\n",
      "Already finished: 200 17.467248908296945\n",
      "\n",
      "\tAcc: 34.333333333333336\n",
      "Already finished: 400 34.93449781659389\n",
      "\n",
      "\tAcc: 34.83333333333334\n",
      "Already finished: 600 52.40174672489083\n",
      "\n",
      "\tAcc: 35.166666666666686\n",
      "Already finished: 800 69.86899563318778\n",
      "\n",
      "\tAcc: 35.91666666666668\n",
      "Already finished: 1000 87.33624454148472\n",
      "\n",
      "\tAcc: 36.833333333333336\n",
      "36.53566229985444\n",
      "1145\n"
     ]
    }
   ],
   "source": [
    "vis=0\n",
    "acc=0.0\n",
    "NUM_CAP=65\n",
    "total={}\n",
    "NUM_KB=5\n",
    "for k,row in enumerate(val_aokvqa):\n",
    "    \"\"\"if vis>5:\n",
    "        break\"\"\"\n",
    "    if k%200==0:\n",
    "        print ('Already finished:',\n",
    "               k,k*100.0/len(val_aokvqa) )\n",
    "        if k>0:\n",
    "            print ('\\n\\tAcc:',acc*100.0/vis)\n",
    "    ques_id=row['question_id']\n",
    "    img_id=str(row['image_id'])\n",
    "    img_id=img_id.zfill(12)+'.jpg'\n",
    "    img_path=os.path.join(PATH,'COCO-2017/val2017',img_id)\n",
    "    im=Image.open(img_path).convert('RGB')\n",
    "    image = vis_processors[\"eval\"](im).unsqueeze(0).to(device)\n",
    "    text=row['question']\n",
    "    question = txt_processors[\"eval\"](text)\n",
    "    samples = {\"image\": image, \"text_input\": [question]}\n",
    "    caption=captions[ques_id]\n",
    "    kb=load_json(os.path.join('../A_OKVQA/cluster_generated_kb',\n",
    "                              ques_id+'.json'))[:NUM_KB]\n",
    "    samples['captions']=[caption[:NUM_CAP]]\n",
    "    samples['captions'][0].extend(kb)\n",
    "    pred_answers = model.forward_qa(samples,\n",
    "                                    num_captions=NUM_CAP+NUM_KB,\n",
    "                                    num_captions_fid=5)\n",
    "    pred=norm_ans(pred_answers[0].lower())\n",
    "    \"\"\"print (text,ans_dict[ques_id])\n",
    "    print (pred)\n",
    "    display(im)\"\"\"\n",
    "    total[ques_id]=pred\n",
    "    if pred in ans_dict[ques_id]:\n",
    "        acc+=get_score(ans_dict[ques_id][pred])\n",
    "    vis+=1\n",
    "print (acc*100.0/vis)\n",
    "print (vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
